{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import config\n",
    "import metrics\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Dataset path\n",
    "    DATASET_DIR: str = 'dataset/'\n",
    "\n",
    "    # Images paths\n",
    "    NORMAL_IMAGES_FOLDER: str = 'dataset/Normal/'\n",
    "    TUBERCULOSIS_IMAGES_FOLDER: str = 'dataset/Tuberculosis'\n",
    "\n",
    "    # Dataframes paths\n",
    "    NORMAL_XLSX_PATH: str = 'dataset/Normal.metadata.xlsx'\n",
    "    TUBERCULOSIS_XLSX_PATH: str = 'dataset/Tuberculosis.metadata.xlsx'\n",
    "\n",
    "    # Hyperparameters\n",
    "    BATCH_SIZE: int = 64\n",
    "    LEARNING_RATE: float = 0.001\n",
    "    NUM_EPOCHS: int = 10\n",
    "    MOMENTUM: float = 0.9\n",
    "    WEIGHT_DECAY: float = 1e-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    @staticmethod\n",
    "    def trim(im):\n",
    "        \"\"\"\n",
    "        Converts image to grayscale using cv2, then computes binary matrix\n",
    "        of the pixels that are above a certain threshold, then takes out\n",
    "        the first row where a certain percentage of the pixels are above the\n",
    "        threshold will be the first clip point. Same idea for col, max row, max col.\n",
    "        \"\"\"\n",
    "        percentage = 0.02\n",
    "\n",
    "        img = np.array(im)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        im = img_gray > 0.1 * np.mean(img_gray[img_gray != 0])\n",
    "        row_sums = np.sum(im, axis=1)\n",
    "        col_sums = np.sum(im, axis=0)\n",
    "        rows = np.where(row_sums > img.shape[1] * percentage)[0]\n",
    "        cols = np.where(col_sums > img.shape[0] * percentage)[0]\n",
    "        min_row, min_col = np.min(rows), np.min(cols)\n",
    "        max_row, max_col = np.max(rows), np.max(cols)\n",
    "        im_crop = img[min_row: max_row + 1, min_col: max_col + 1]\n",
    "        return Image.fromarray(im_crop)\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_images_with_labels(data_df, num_images=5, random_seed=42, show_image_mode=True):\n",
    "        \"\"\"\n",
    "        Plot some images with their corresponding labels from the given DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data_df (pd.DataFrame): The DataFrame containing 'filepaths' and 'labels' columns.\n",
    "            num_images (int, optional): Number of images to plot. Defaults to 5.\n",
    "            random_seed (int, optional): Random seed for reproducibility. Defaults to 42.\n",
    "            show_image_mode (bool, optional): Whether to show image mode (RGB or not) alongside the labels. \n",
    "                                              Defaults to True.\n",
    "        \"\"\"\n",
    "        random.seed(random_seed)\n",
    "        sampled_data = data_df.sample(n=num_images)\n",
    "\n",
    "        num_rows = (num_images - 1) // 5 + 1\n",
    "        num_cols = min(num_images, 5)\n",
    "\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))\n",
    "        for idx, (filepath, label) in enumerate(zip(sampled_data['filepaths'], sampled_data['labels'])):\n",
    "            image = Image.open(filepath)\n",
    "\n",
    "            row_idx = idx // 5\n",
    "            col_idx = idx % 5\n",
    "\n",
    "            axes[row_idx, col_idx].imshow(image)\n",
    "            axes[row_idx, col_idx].axis('off')\n",
    "\n",
    "            if show_image_mode:\n",
    "                is_rgb = image.mode == 'RGB'\n",
    "                axes[row_idx, col_idx].set_title(f'Label: {label} | RGB: {is_rgb}')\n",
    "            else:\n",
    "                axes[row_idx, col_idx].set_title(f'Label: {label}')\n",
    "\n",
    "        for idx in range(num_images, num_rows * 5):\n",
    "            row_idx = idx // 5\n",
    "            col_idx = idx % 5\n",
    "            fig.delaxes(axes[row_idx, col_idx])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def resize_and_save_images(data_df, save_dir, new_size=(224, 224)):\n",
    "        \"\"\"\n",
    "        Resize images from the DataFrame and save them to the specified directory.\n",
    "\n",
    "        Args:\n",
    "            data_df (pd.DataFrame): The DataFrame containing 'filepaths' and 'labels' columns.\n",
    "            save_dir (str): The directory path where the resized images will be saved.\n",
    "            new_size (tuple, optional): The new size to which the images will be resized. Defaults to (224, 224).\n",
    "        \"\"\"\n",
    "        # Create the save directories if they don't exist\n",
    "        normal_save_dir = os.path.join(save_dir, 'Normal')\n",
    "        tuberculosis_save_dir = os.path.join(save_dir, 'Tuberculosis')\n",
    "        os.makedirs(normal_save_dir, exist_ok=True)\n",
    "        os.makedirs(tuberculosis_save_dir, exist_ok=True)\n",
    "\n",
    "        for filepath, label in tqdm(zip(data_df['filepaths'], data_df['labels'])):\n",
    "            image = cv2.imread(filepath)\n",
    "            trimmed_image = np.array(Utils.trim(image))\n",
    "            resized_image = cv2.resize(trimmed_image, new_size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            if label == 'Normal':\n",
    "                label_save_dir = normal_save_dir\n",
    "            else:\n",
    "                label_save_dir = tuberculosis_save_dir\n",
    "\n",
    "            filename_without_ext = os.path.splitext(os.path.basename(filepath))[0]\n",
    "\n",
    "            save_filename = f\"{filename_without_ext}.png\"\n",
    "            save_path = os.path.join(label_save_dir, save_filename)\n",
    "            cv2.imwrite(save_path, resized_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepaths_and_labels(sdir):\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    classlist = sorted(os.listdir(sdir))\n",
    "    for _class in classlist:\n",
    "        classpath = os.path.join(sdir, _class)\n",
    "        if os.path.isdir(classpath):\n",
    "            flist = sorted(os.listdir(classpath))\n",
    "            for f in tqdm(flist, ncols=130, desc=f'{_class:25s}', unit='files', colour='blue'):\n",
    "                fpath = os.path.join(classpath, f)\n",
    "                filepaths.append(fpath)\n",
    "\n",
    "                if _class == 'Augmented_normal':\n",
    "                    _class = 'Normal'\n",
    "                elif _class == 'Augmented_tuberculosis':\n",
    "                    _class = 'Tuberculosis'\n",
    "                    \n",
    "                labels.append(_class)\n",
    "    return filepaths, labels\n",
    "\n",
    "def create_dataframes(filepaths, labels):\n",
    "    Fseries = pd.Series(filepaths, name='filepaths')\n",
    "    Lseries = pd.Series(labels, name='labels')\n",
    "    df = pd.concat([Fseries, Lseries], axis=1)\n",
    "    return df\n",
    "\n",
    "def split_data(df):\n",
    "    train_df, dummy_df = train_test_split(df, train_size=.8, shuffle=True, random_state=123, stratify=df['labels'])\n",
    "    valid_df, test_df = train_test_split(dummy_df, train_size=.5, shuffle=True, random_state=123, stratify=dummy_df['labels'])\n",
    "    return train_df, test_df, valid_df\n",
    "\n",
    "def calculate_average_image_size(df, num_samples=50):\n",
    "    sample_df = df.sample(n=num_samples, replace=False)\n",
    "    ht = 0\n",
    "    wt = 0\n",
    "    count = 0\n",
    "    for i in range(len(sample_df)):\n",
    "        fpath = sample_df['filepaths'].iloc[i]\n",
    "        try:\n",
    "            img = cv2.imread(fpath)\n",
    "            h, w, _ = img.shape\n",
    "            wt += w\n",
    "            ht += h\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "    average_height = int(ht / count)\n",
    "    average_weight = int(wt / count)\n",
    "    aspect_ratio = average_height / average_weight\n",
    "    return average_height,average_weight,aspect_ratio\n",
    "\n",
    "\n",
    "def make_dataframes(sdir):\n",
    "    filepaths, labels = get_filepaths_and_labels(sdir)\n",
    "    df = create_dataframes(filepaths, labels)\n",
    "    train_df, test_df, valid_df = split_data(df)\n",
    "    average_height, average_weight, aspect_ratio = calculate_average_image_size(train_df)\n",
    "    \n",
    "    # Other statistics and information can be printed here if needed.\n",
    "    class_count = len(train_df['labels'].unique())\n",
    "    counts = list(train_df['labels'].value_counts())\n",
    "    \n",
    "    return train_df, test_df, valid_df, class_count, average_height, average_weight, aspect_ratio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils import trim\n",
    "\n",
    "class Augmentation:\n",
    "    def __init__(self, output_path, probability=0.4):\n",
    "        self.output_path = output_path\n",
    "        self.probability = probability\n",
    "\n",
    "    def random_rotation(self, image, angle_range=(-30, 30)):\n",
    "        if random.random() < self.probability:\n",
    "            angle = random.uniform(angle_range[0], angle_range[1])\n",
    "            h, w = image.shape[:2]\n",
    "            center = (w / 2, h / 2)\n",
    "            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            image = cv2.warpAffine(image, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR)\n",
    "        return image\n",
    "\n",
    "    def random_flip(self, image):\n",
    "        if random.random() < self.probability:\n",
    "            image = cv2.flip(image, 1)  # Horizontal flip\n",
    "        return image\n",
    "    \n",
    "    def random_zoom(self, image, zoom_range=(0.8, 1.2)):\n",
    "        if random.random() < self.probability:\n",
    "            zoom_factor = random.uniform(zoom_range[0], zoom_range[1])\n",
    "            h, w = image.shape[:2]\n",
    "\n",
    "            # Calculate new zoomed image size\n",
    "            new_h, new_w = int(h * zoom_factor), int(w * zoom_factor)\n",
    "\n",
    "            # Ensure the new size does not exceed the original size\n",
    "            if new_h >= h:\n",
    "                new_h = h - 1\n",
    "            if new_w >= w:\n",
    "                new_w = w - 1\n",
    "\n",
    "            # Resize the image\n",
    "            zoomed_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            # Compute border size for padding\n",
    "            top = (h - new_h) // 2\n",
    "            bottom = h - new_h - top\n",
    "            left = (w - new_w) // 2\n",
    "            right = w - new_w - left\n",
    "\n",
    "            # Pad the zoomed image to the original size\n",
    "            image = cv2.copyMakeBorder(zoomed_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def color_jittering(self, image, jitter_range=20):\n",
    "        if random.random() < self.probability:\n",
    "            b, g, r = cv2.split(image)\n",
    "            b = np.clip(b.astype(np.int32) + random.randint(-jitter_range, jitter_range), 0, 255).astype(np.uint8)\n",
    "            g = np.clip(g.astype(np.int32) + random.randint(-jitter_range, jitter_range), 0, 255).astype(np.uint8)\n",
    "            r = np.clip(r.astype(np.int32) + random.randint(-jitter_range, jitter_range), 0, 255).astype(np.uint8)\n",
    "            image = cv2.merge((b, g, r))\n",
    "        return image\n",
    "\n",
    "\n",
    "    def __call__(self, image_path,index,class_name):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Load as a color image\n",
    "\n",
    "        # Apply augmentations\n",
    "        image = self.random_rotation(image)\n",
    "        image = self.random_flip(image)\n",
    "        image = self.random_zoom(image)\n",
    "        image = self.color_jittering(image)\n",
    "        image = np.array(trim(image))\n",
    "        # Save the augmented image\n",
    "        filename = os.path.basename(image_path)\n",
    "        output_image_path = os.path.join(self.output_path, f\"Augment-{class_name}-{index}.png\")\n",
    "        cv2.imwrite(output_image_path, np.array(trim(image)))\n",
    "        return image\n",
    "\n",
    "\n",
    "def augmentation_main():\n",
    "    # Define input and output directories\n",
    "    input_dir = 'resized_dataset'\n",
    "    output_dir_normal = os.path.join(input_dir, 'Augmented_normal')\n",
    "    output_dir_tuberculous = os.path.join(input_dir, 'Augmented_tuberculosis')\n",
    "\n",
    "    # Create output directories if they don't exist\n",
    "    os.makedirs(output_dir_normal, exist_ok=True)\n",
    "    os.makedirs(output_dir_tuberculous, exist_ok=True)\n",
    "\n",
    "    # Create the Augmentation objects\n",
    "    augmentor_normal = Augmentation(output_path=output_dir_normal, probability=0.6)  # Set lower probability for Normal images\n",
    "    augmentor_tb = Augmentation(output_path=output_dir_tuberculous, probability=0.8)  # Set higher probability for TB images\n",
    "\n",
    "    # Augment Normal images (randomly choose 500 samples)\n",
    "    normal_images_dir = os.path.join(input_dir, 'Normal')\n",
    "    normal_images = os.listdir(normal_images_dir)\n",
    "    selected_normal_images = random.sample(normal_images, 500)\n",
    "    num = 1\n",
    "    for img_file in tqdm(selected_normal_images):\n",
    "        img_path = os.path.join(normal_images_dir, img_file)\n",
    "        augmented_image = augmentor_normal(img_path,index=num,class_name='Normal')\n",
    "        num+=1\n",
    "\n",
    "    # Augment Tuberculous images to have a total of 2000 augmented images\n",
    "    tb_images_dir = os.path.join(input_dir, 'Tuberculosis')\n",
    "    tb_images = os.listdir(tb_images_dir)\n",
    "    num_tb_images = 700\n",
    "    num_augmentations_needed = 2000 - num_tb_images\n",
    "\n",
    "    for i in tqdm(range(num_augmentations_needed)):\n",
    "        img_file = random.choice(tb_images)\n",
    "        img_path = os.path.join(tb_images_dir, img_file)\n",
    "        augmented_image = augmentor_tb(img_path,index=i+1,class_name='Tuberculosis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positive(y_true,y_pred):\n",
    "    return ((y_true == 1) & (y_pred == 1)).sum().item()\n",
    "\n",
    "def true_negative(y_true,y_pred):\n",
    "    return ((y_true == 0) & (y_pred == 0)).sum().item()\n",
    "\n",
    "def false_positive(y_true,y_pred):\n",
    "    return ((y_true == 0) & (y_pred == 1)).sum().item()\n",
    "\n",
    "def false_negative(y_true,y_pred):\n",
    "    return ((y_true == 1) & (y_pred == 0)).sum().item()\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    return tp / (tp + fp + 1e-7)\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    return tp / (tp + fn + 1e-7) \n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * (prec * rec) / (prec + rec + 1e-7)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    total_samples = y_true.shape[0]\n",
    "    return (tp + tn) / total_samples\n",
    "\n",
    "\n",
    "\n",
    "class F1ScoreCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self,weight=None,alpha=1.0, beta=0.5, epsilon=1e-7):\n",
    "        super(F1ScoreCrossEntropyLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.epsilon = epsilon\n",
    "        self.cross_entropy = nn.CrossEntropyLoss(weight=weight)\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        _, y_pred_final = torch.max(y_pred, 1)\n",
    "        y_true_np = y_true.cpu().numpy()\n",
    "        y_pred_np = y_pred_final.cpu().numpy()\n",
    "        f1 = f1_score(y_true_np, y_pred_np)\n",
    "        ce_loss = self.cross_entropy(y_pred, y_true)\n",
    "        \n",
    "        loss = self.alpha * ce_loss - self.beta * torch.log(torch.tensor(f1) + self.epsilon) + 1\n",
    "        return loss.mean()\n",
    "    \n",
    "# this loss caculate new weight base on f1score each mini batch \n",
    "class F1_Loss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, y_pred, y_true,):\n",
    "        y_true_one_hot = F.one_hot(y_true.to(torch.int64), 2).to(torch.float32)\n",
    "        \n",
    "        tp = (y_true_one_hot * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true_one_hot) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true_one_hot) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true_one_hot * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n",
    "        f1=f1.detach()\n",
    "        CE =torch.nn.CrossEntropyLoss(weight=( 1 - f1))(y_pred, y_true_one_hot)\n",
    "        return  CE.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform if transform is not None else self._default_transform()\n",
    "        self.class_labels = {'Normal': 0, 'Tuberculosis': 1}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"TBDataset: Number of samples: {len(self)}\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filepath = self.data_df.iloc[index, 0]\n",
    "        label = self.data_df.iloc[index, 1]\n",
    "\n",
    "        # Load image using PIL\n",
    "        image = Image.open(filepath)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def _default_transform(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(train_transform,valid_transform,test_transform,config):\n",
    "    train_df, test_df, valid_df, class_count, average_height, average_weight, aspect_ratio = make_dataframes(config.DATASET_DIR)\n",
    "    train_dataset = TBDataset(train_df, transform=train_transform)\n",
    "    valid_dataset = TBDataset(valid_df, transform=valid_transform)\n",
    "    test_dataset = TBDataset(test_df, transform=test_transform)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    valid_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_dataloader,valid_dataloader,test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, criterion, optimizer, train_loader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to(config.DEVICE), labels.to(config.DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    return running_loss / len(train_loader.dataset)\n",
    "\n",
    "# Testing loop\n",
    "def test(model, criterion, test_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader):\n",
    "            images, labels = images.to(config.DEVICE), labels.to(config.DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            # print(\"labels shape\",labels.shape,\"pred shape\",predicted.shape)\n",
    "            pred_labels.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    avg_loss = running_loss / len(test_loader.dataset)\n",
    "    true_labels = torch.tensor(true_labels)\n",
    "    pred_labels = torch.tensor(pred_labels)\n",
    "    acc = metrics.accuracy(true_labels, pred_labels)\n",
    "    macro_f1 = metrics.f1_score(true_labels, pred_labels)\n",
    "\n",
    "    return avg_loss, acc, macro_f1\n",
    "\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, train_loader, val_loader,test_loader,num_epochs, log_file, save_dir):\n",
    "    train_losses = np.zeros(num_epochs)\n",
    "    val_losses = np.zeros(num_epochs)\n",
    "    val_accuracies = np.zeros(num_epochs)\n",
    "    val_f1_scores = np.zeros(num_epochs)\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, criterion, optimizer, train_loader)\n",
    "        val_loss, val_acc, macro_f1 = test(model, criterion, val_loader)\n",
    "        train_losses[epoch] = train_loss\n",
    "        val_losses[epoch] = val_loss\n",
    "        val_accuracies[epoch] = val_acc\n",
    "        val_f1_scores[epoch] = macro_f1\n",
    "        utils.log_training_process(epoch, train_loss, val_loss, val_acc, macro_f1)\n",
    "        print(f\"Epoch {epoch+1} | train_loss: {train_loss:.3f} | val_loss: {val_loss:.3f} | val_acc: {val_acc:.3f} | f1_score: {macro_f1:.3f}\")\n",
    "        # Save the model with the best validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            torch.save({\n",
    "                \"epoch\":epoch,\n",
    "                \"model_state_dict\":model.state_dict(),\n",
    "                \"optimizer_state_dict\":optimizer.state_dict(),\n",
    "                \"train_loss\":train_loss,\n",
    "                \"val_loss\":val_loss,\n",
    "                \"val_accuracy\":val_acc,\n",
    "                \"val_f1_score\":macro_f1\n",
    "            },config.LOGFILE)\n",
    "\n",
    "    test_loss, test_acc, test_macro_f1 = test(model,criterion,test_loader)\n",
    "    print(f\"test_loss: {test_loss:.3f} | test_acc: {test_acc:.3f} | f1_score: {test_macro_f1:.3f}\")\n",
    "\n",
    "    print(\"Training completed!\")\n",
    "    return train_losses,val_losses,val_accuracies,val_f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
