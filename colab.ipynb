{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Dataset path\n",
    "    DATASET_DIR: str = 'dataset/'\n",
    "\n",
    "    # Images paths\n",
    "    NORMAL_IMAGES_FOLDER: str = 'dataset/Normal/'\n",
    "    TUBERCULOSIS_IMAGES_FOLDER: str = 'dataset/Tuberculosis'\n",
    "\n",
    "    # Dataframes paths\n",
    "    NORMAL_XLSX_PATH: str = 'dataset/Normal.metadata.xlsx'\n",
    "    TUBERCULOSIS_XLSX_PATH: str = 'dataset/Tuberculosis.metadata.xlsx'\n",
    "\n",
    "    # Hyperparameters\n",
    "    BATCH_SIZE: int = 64\n",
    "    LEARNING_RATE: float = 0.001\n",
    "    NUM_EPOCHS: int = 10\n",
    "    MOMENTUM: float = 0.9\n",
    "    WEIGHT_DECAY: float = 1e-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    @staticmethod\n",
    "    def trim(im):\n",
    "        \"\"\"\n",
    "        Converts image to grayscale using cv2, then computes binary matrix\n",
    "        of the pixels that are above a certain threshold, then takes out\n",
    "        the first row where a certain percentage of the pixels are above the\n",
    "        threshold will be the first clip point. Same idea for col, max row, max col.\n",
    "        \"\"\"\n",
    "        percentage = 0.02\n",
    "\n",
    "        img = np.array(im)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        im = img_gray > 0.1 * np.mean(img_gray[img_gray != 0])\n",
    "        row_sums = np.sum(im, axis=1)\n",
    "        col_sums = np.sum(im, axis=0)\n",
    "        rows = np.where(row_sums > img.shape[1] * percentage)[0]\n",
    "        cols = np.where(col_sums > img.shape[0] * percentage)[0]\n",
    "        min_row, min_col = np.min(rows), np.min(cols)\n",
    "        max_row, max_col = np.max(rows), np.max(cols)\n",
    "        im_crop = img[min_row: max_row + 1, min_col: max_col + 1]\n",
    "        return Image.fromarray(im_crop)\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_images_with_labels(data_df, num_images=5, random_seed=42, show_image_mode=True):\n",
    "        \"\"\"\n",
    "        Plot some images with their corresponding labels from the given DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data_df (pd.DataFrame): The DataFrame containing 'filepaths' and 'labels' columns.\n",
    "            num_images (int, optional): Number of images to plot. Defaults to 5.\n",
    "            random_seed (int, optional): Random seed for reproducibility. Defaults to 42.\n",
    "            show_image_mode (bool, optional): Whether to show image mode (RGB or not) alongside the labels. \n",
    "                                              Defaults to True.\n",
    "        \"\"\"\n",
    "        random.seed(random_seed)\n",
    "        sampled_data = data_df.sample(n=num_images)\n",
    "\n",
    "        num_rows = (num_images - 1) // 5 + 1\n",
    "        num_cols = min(num_images, 5)\n",
    "\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))\n",
    "        for idx, (filepath, label) in enumerate(zip(sampled_data['filepaths'], sampled_data['labels'])):\n",
    "            image = Image.open(filepath)\n",
    "\n",
    "            row_idx = idx // 5\n",
    "            col_idx = idx % 5\n",
    "\n",
    "            axes[row_idx, col_idx].imshow(image)\n",
    "            axes[row_idx, col_idx].axis('off')\n",
    "\n",
    "            if show_image_mode:\n",
    "                is_rgb = image.mode == 'RGB'\n",
    "                axes[row_idx, col_idx].set_title(f'Label: {label} | RGB: {is_rgb}')\n",
    "            else:\n",
    "                axes[row_idx, col_idx].set_title(f'Label: {label}')\n",
    "\n",
    "        for idx in range(num_images, num_rows * 5):\n",
    "            row_idx = idx // 5\n",
    "            col_idx = idx % 5\n",
    "            fig.delaxes(axes[row_idx, col_idx])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def resize_and_save_images(data_df, save_dir, new_size=(224, 224)):\n",
    "        \"\"\"\n",
    "        Resize images from the DataFrame and save them to the specified directory.\n",
    "\n",
    "        Args:\n",
    "            data_df (pd.DataFrame): The DataFrame containing 'filepaths' and 'labels' columns.\n",
    "            save_dir (str): The directory path where the resized images will be saved.\n",
    "            new_size (tuple, optional): The new size to which the images will be resized. Defaults to (224, 224).\n",
    "        \"\"\"\n",
    "        # Create the save directories if they don't exist\n",
    "        normal_save_dir = os.path.join(save_dir, 'Normal')\n",
    "        tuberculosis_save_dir = os.path.join(save_dir, 'Tuberculosis')\n",
    "        os.makedirs(normal_save_dir, exist_ok=True)\n",
    "        os.makedirs(tuberculosis_save_dir, exist_ok=True)\n",
    "\n",
    "        for filepath, label in tqdm(zip(data_df['filepaths'], data_df['labels'])):\n",
    "            image = cv2.imread(filepath)\n",
    "            trimmed_image = np.array(Utils.trim(image))\n",
    "            resized_image = cv2.resize(trimmed_image, new_size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            if label == 'Normal':\n",
    "                label_save_dir = normal_save_dir\n",
    "            else:\n",
    "                label_save_dir = tuberculosis_save_dir\n",
    "\n",
    "            filename_without_ext = os.path.splitext(os.path.basename(filepath))[0]\n",
    "\n",
    "            save_filename = f\"{filename_without_ext}.png\"\n",
    "            save_path = os.path.join(label_save_dir, save_filename)\n",
    "            cv2.imwrite(save_path, resized_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepaths_and_labels(sdir):\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    classlist = sorted(os.listdir(sdir))\n",
    "    for _class in classlist:\n",
    "        classpath = os.path.join(sdir, _class)\n",
    "        if os.path.isdir(classpath):\n",
    "            flist = sorted(os.listdir(classpath))\n",
    "            for f in tqdm(flist, ncols=130, desc=f'{_class:25s}', unit='files', colour='blue'):\n",
    "                fpath = os.path.join(classpath, f)\n",
    "                filepaths.append(fpath)\n",
    "                labels.append(_class)\n",
    "    return filepaths, labels\n",
    "\n",
    "def create_dataframes(filepaths, labels):\n",
    "    Fseries = pd.Series(filepaths, name='filepaths')\n",
    "    Lseries = pd.Series(labels, name='labels')\n",
    "    df = pd.concat([Fseries, Lseries], axis=1)\n",
    "    return df\n",
    "\n",
    "def split_data(df):\n",
    "    train_df, dummy_df = train_test_split(df, train_size=.8, shuffle=True, random_state=123, stratify=df['labels'])\n",
    "    valid_df, test_df = train_test_split(dummy_df, train_size=.5, shuffle=True, random_state=123, stratify=dummy_df['labels'])\n",
    "    return train_df, test_df, valid_df\n",
    "\n",
    "def calculate_average_image_size(df, num_samples=50):\n",
    "    sample_df = df.sample(n=num_samples, replace=False)\n",
    "    ht = 0\n",
    "    wt = 0\n",
    "    count = 0\n",
    "    for i in range(len(sample_df)):\n",
    "        fpath = sample_df['filepaths'].iloc[i]\n",
    "        try:\n",
    "            img = cv2.imread(fpath)\n",
    "            h, w, _ = img.shape\n",
    "            wt += w\n",
    "            ht += h\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "    average_height = int(ht / count)\n",
    "    average_weight = int(wt / count)\n",
    "    aspect_ratio = average_height / average_weight\n",
    "    return average_height,average_weight,aspect_ratio\n",
    "\n",
    "\n",
    "def make_dataframes(sdir):\n",
    "    filepaths, labels = get_filepaths_and_labels(sdir)\n",
    "    df = create_dataframes(filepaths, labels)\n",
    "    train_df, test_df, valid_df = split_data(df)\n",
    "    average_height, average_weight, aspect_ratio = calculate_average_image_size(train_df)\n",
    "    \n",
    "    # Other statistics and information can be printed here if needed.\n",
    "    class_count = len(train_df['labels'].unique())\n",
    "    counts = list(train_df['labels'].value_counts())\n",
    "    \n",
    "    return train_df, test_df, valid_df, class_count, average_height, average_weight, aspect_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform if transform is not None else self._default_transform()\n",
    "        self.class_labels = {'Normal': 0, 'Tuberculosis': 1}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"TBDataset: Number of samples: {len(self)}\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filepath = self.data_df.iloc[index, 0]\n",
    "        label = self.data_df.iloc[index, 1]\n",
    "\n",
    "        # Load image using PIL\n",
    "        image = Image.open(filepath)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def _default_transform(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(train_transform,valid_transform,test_transform,config):\n",
    "    train_df, test_df, valid_df, class_count, average_height, average_weight, aspect_ratio = make_dataframes(config.DATASET_DIR)\n",
    "    train_dataset = TBDataset(train_df, transform=train_transform)\n",
    "    valid_dataset = TBDataset(valid_df, transform=valid_transform)\n",
    "    test_dataset = TBDataset(test_df, transform=test_transform)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    valid_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_dataloader,valid_dataloader,test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
